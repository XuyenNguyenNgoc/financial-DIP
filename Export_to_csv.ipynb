{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TgD9Igi1Ifk6",
        "outputId": "71c39e80-74d5-4045-9412-c929c1795b0e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Database initialized\n",
            "\n",
            "üìÅ Processing: VNY_000000014707127_3.1_VI_VNY_Bao_cao_tai_chinh_hop_nhat_nam_2024da_nen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  VNY_000000014707127_3.1_VI_VNY_Bao_cao_tai_chinh_hop_nhat_nam_2024da_nen: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 44.62it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: WTC_000000014694194_Bao_cao_TC_2024_sau_KT_ky_so\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  WTC_000000014694194_Bao_cao_TC_2024_sau_KT_ky_so: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 40.75it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: SBD_000000015054784_VI_BaoCaoTaiChinhKiemToan_Hop_Nhat_2024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  SBD_000000015054784_VI_BaoCaoTaiChinhKiemToan_Hop_Nhat_2024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5/5 [00:00<00:00, 98.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: BOT_000000014944415_VI_Baocaotaichinh_kiemtoan_2024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  BOT_000000014944415_VI_Baocaotaichinh_kiemtoan_2024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 81.86it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: DCS_000000014779169_VI_BaoCaoTaiChinh_KiemToan__2022.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  DCS_000000014779169_VI_BaoCaoTaiChinh_KiemToan__2022.: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 8/8 [00:00<00:00, 75.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: PVE_000000014779385_VI_BaoCaoTaiChinh_KiemToan_2024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  PVE_000000014779385_VI_BaoCaoTaiChinh_KiemToan_2024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12/12 [00:00<00:00, 189.68it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: VXB_000000013563283_CBTT_BCTC_2023_F\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  VXB_000000013563283_CBTT_BCTC_2023_F: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 44.94it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: CT6_000000014858118_Bao_cao_kiem_toan_tieng_Vietda_nen\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  CT6_000000014858118_Bao_cao_kiem_toan_tieng_Vietda_nen: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 43.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: BVL_000000014725614_VI_BCTC_hop_nhat_2024.signed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  BVL_000000014725614_VI_BCTC_hop_nhat_2024.signed: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 42.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: VE1_000000014753067_VI_BCTC_nam_2024_da_kiem_toan_da_ky_VE1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  VE1_000000014753067_VI_BCTC_nam_2024_da_kiem_toan_da_ky_VE1: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 46.38it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: TNA_000000015568133_VI_BaoCaoTaiChinhHopNhatNam2023\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  TNA_000000015568133_VI_BaoCaoTaiChinhHopNhatNam2023: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 36.72it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: VHG_000000014706961_VI_BaoCaoTaiChinh_KiemToan_2024.pdf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  VHG_000000014706961_VI_BaoCaoTaiChinh_KiemToan_2024.pdf: 0it [00:00, ?it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: BT6_000000014970920_VI_BaoCaoTaiChinh_KiemToan_2024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  BT6_000000014970920_VI_BaoCaoTaiChinh_KiemToan_2024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 43.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: VXP_000000014852285_CBTT_BCTC_kiem_toan_2024_dinh_kem.signed\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  VXP_000000014852285_CBTT_BCTC_kiem_toan_2024_dinh_kem.signed: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 47.10it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: UNI_000000014739023_VI_BaoCaoTaiChinh_KiemToan_2024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  UNI_000000014739023_VI_BaoCaoTaiChinh_KiemToan_2024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 9/9 [00:00<00:00, 114.48it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: BT6_000000014970920_VI_BaoCaoTaiChinh_KiemToan_2024 (1)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  BT6_000000014970920_VI_BaoCaoTaiChinh_KiemToan_2024 (1): 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 45.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: SIG_000000014701703_Bao_cao_tai_chinh_hop_nhat_nam_2024__Signed_kem_giai_trinh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  SIG_000000014701703_Bao_cao_tai_chinh_hop_nhat_nam_2024__Signed_kem_giai_trinh: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 17.89it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: APP_000000014774810_BCTC_Kiem_toan_2024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  APP_000000014774810_BCTC_Kiem_toan_2024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 44.92it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: AMV_000000015013462_VN_BCTC_HN_nam_2024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  AMV_000000015013462_VN_BCTC_HN_nam_2024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 38.57it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: PLO_000000015011094_Bao_cao_tai_chinh_da_kiem_toan_nam_2024_sign\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  PLO_000000015011094_Bao_cao_tai_chinh_da_kiem_toan_nam_2024_sign: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4/4 [00:00<00:00, 64.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: TIG_000000014780156_VI_Baocaotaichinhhopnhat_kiemtoan_2024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  TIG_000000014780156_VI_Baocaotaichinhhopnhat_kiemtoan_2024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 3/3 [00:00<00:00, 46.90it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: CMI_000000014698416_VI_BaoCaoTaiChinh_KiemToan_2024\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  CMI_000000014698416_VI_BaoCaoTaiChinh_KiemToan_2024: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 42.70it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üìÅ Processing: CMC_000000014715923_VI_BaoCaoTaiChinh_KiemToan_2024.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "  CMC_000000014715923_VI_BaoCaoTaiChinh_KiemToan_2024.: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:00<00:00, 37.80it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "============================================================\n",
            "‚úÖ PROCESSING COMPLETE!\n",
            "üìä Statistics:\n",
            "   - Total files scanned: 79\n",
            "   - Successfully processed: 55\n",
            "   - Skipped (insufficient data): 24\n",
            "   - Total records inserted: 1143\n",
            "üíæ Database saved to: /content/financial_data.db\n",
            "============================================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ],
      "source": [
        "# =========================\n",
        "# HTML TABLE ‚Üí DATABASE PARSER\n",
        "# =========================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import sqlite3\n",
        "from bs4 import BeautifulSoup\n",
        "from tqdm import tqdm\n",
        "import unicodedata\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "BASE_DIR = \"/content\"\n",
        "HTML_BASE_DIR = os.path.join(BASE_DIR, \"html\")\n",
        "DB_PATH = os.path.join(BASE_DIR, \"financial_data.db\")\n",
        "\n",
        "# =========================\n",
        "# UTILS\n",
        "# =========================\n",
        "\n",
        "def remove_accents(text):\n",
        "    \"\"\"Lo·∫°i b·ªè d·∫•u ti·∫øng Vi·ªát ƒë·ªÉ so s√°nh\"\"\"\n",
        "    nfd = unicodedata.normalize('NFD', text)\n",
        "    return ''.join(char for char in nfd if unicodedata.category(char) != 'Mn')\n",
        "\n",
        "def clean_number(text):\n",
        "    \"\"\"\n",
        "    L√†m s·∫°ch s·ªë li·ªáu:\n",
        "    - GI·ªÆ NGUY√äN d·∫•u ngo·∫∑c () v√¨ n√≥ bi·ªÉu th·ªã s·ªë √¢m trong k·∫ø to√°n\n",
        "    - Lo·∫°i b·ªè d·∫•u ch·∫•m ph√¢n c√°ch h√†ng ngh√¨n\n",
        "    - Thay d·∫•u ph·∫©y th√†nh d·∫•u ch·∫•m th·∫≠p ph√¢n\n",
        "    - N·∫øu c√≥ kho·∫£ng tr·∫Øng, so s√°nh ƒë·ªô d√†i d√£y s·ªë:\n",
        "      + D√£y s·ªë n√†o d√†i h∆°n th√¨ l·∫•y\n",
        "      + N·∫øu b·∫±ng nhau, ∆∞u ti√™n l·∫•y c√°i tr∆∞·ªõc kho·∫£ng tr·∫Øng\n",
        "    - Tr·∫£ v·ªÅ STRING (kh√¥ng ph·∫£i float) ƒë·ªÉ gi·ªØ nguy√™n format\n",
        "    \"\"\"\n",
        "    if not text or not isinstance(text, str):\n",
        "        return None\n",
        "\n",
        "    text = text.strip()\n",
        "\n",
        "    # Ki·ªÉm tra xem c√≥ ngo·∫∑c kh√¥ng (s·ªë √¢m trong k·∫ø to√°n)\n",
        "    has_parentheses = '(' in text or ')' in text\n",
        "\n",
        "    # Lo·∫°i b·ªè c√°c k√Ω t·ª± kh√¥ng ph·∫£i s·ªë/ngo·∫∑c/d·∫•u (gi·ªØ ngo·∫∑c, s·ªë, d·∫•u tr·ª´, d·∫•u ph·∫©y, d·∫•u ch·∫•m)\n",
        "    text = re.sub(r'[^\\d\\-.,\\s()()]', '', text)\n",
        "\n",
        "    # X·ª≠ l√Ω kho·∫£ng tr·∫Øng: so s√°nh ƒë·ªô d√†i d√£y s·ªë\n",
        "    if ' ' in text:\n",
        "        parts = [p.strip() for p in text.split(' ') if p.strip()]\n",
        "\n",
        "        # L·ªçc c√°c ph·∫ßn c√≥ ch·ª©a s·ªë\n",
        "        number_parts = []\n",
        "        for part in parts:\n",
        "            # L√†m s·∫°ch part t·∫°m th·ªùi ƒë·ªÉ ƒë·∫øm (b·ªè d·∫•u ch·∫•m, ph·∫©y)\n",
        "            clean_part = part.replace('.', '').replace(',', '').replace('(', '').replace(')', '')\n",
        "            if re.search(r'\\d', clean_part):\n",
        "                # ƒê·∫øm s·ªë ch·ªØ s·ªë (kh√¥ng t√≠nh d·∫•u ch·∫•m, ph·∫©y, tr·ª´, ngo·∫∑c)\n",
        "                digit_count = len(re.findall(r'\\d', clean_part))\n",
        "                number_parts.append((part, digit_count))\n",
        "\n",
        "        if number_parts:\n",
        "            # S·∫Øp x·∫øp theo ƒë·ªô d√†i (gi·∫£m d·∫ßn), n·∫øu b·∫±ng nhau th√¨ gi·ªØ th·ª© t·ª± g·ªëc (∆∞u ti√™n ph·∫ßn ƒë·∫ßu)\n",
        "            number_parts.sort(key=lambda x: x[1], reverse=True)\n",
        "            text = number_parts[0][0]\n",
        "        else:\n",
        "            # Kh√¥ng c√≥ s·ªë h·ª£p l·ªá\n",
        "            return None\n",
        "\n",
        "    # Lo·∫°i b·ªè d·∫•u ch·∫•m (ph√¢n c√°ch h√†ng ngh√¨n) nh∆∞ng GI·ªÆ ngo·∫∑c\n",
        "    text = text.replace('.', '')\n",
        "\n",
        "    # Thay d·∫•u ph·∫©y th√†nh d·∫•u ch·∫•m (ph√¢n c√°ch th·∫≠p ph√¢n)\n",
        "    text = text.replace(',', '.')\n",
        "\n",
        "    # Lo·∫°i b·ªè kho·∫£ng tr·∫Øng\n",
        "    text = text.replace(' ', '')\n",
        "\n",
        "    # Ki·ªÉm tra xem c√≥ s·ªë kh√¥ng\n",
        "    if not re.search(r'\\d', text):\n",
        "        return None\n",
        "\n",
        "    # N·∫øu c√≥ ngo·∫∑c, gi·ªØ nguy√™n format v·ªõi ngo·∫∑c\n",
        "    if has_parentheses and ('(' in text or ')' in text):\n",
        "        # ƒê·∫£m b·∫£o format ƒë√∫ng: (s·ªë)\n",
        "        # Lo·∫°i b·ªè d·∫•u tr·ª´ n·∫øu c√≥ (v√¨ ngo·∫∑c ƒë√£ bi·ªÉu th·ªã s·ªë √¢m)\n",
        "        text = text.replace('-', '')\n",
        "        # Chu·∫©n h√≥a ngo·∫∑c\n",
        "        if '(' not in text and ')' in text:\n",
        "            text = '(' + text\n",
        "        if '(' in text and ')' not in text:\n",
        "            text = text + ')'\n",
        "        return text\n",
        "\n",
        "    # N·∫øu kh√¥ng c√≥ ngo·∫∑c, tr·∫£ v·ªÅ string s·ªë\n",
        "    # Lo·∫°i b·ªè ngo·∫∑c n·∫øu c√≥ (tr∆∞·ªùng h·ª£p ngo·∫∑c b·ªã t√°ch)\n",
        "    text = text.replace('(', '').replace(')', '')\n",
        "\n",
        "    # Validate l√† s·ªë h·ª£p l·ªá\n",
        "    try:\n",
        "        float(text)\n",
        "        return text\n",
        "    except (ValueError, AttributeError):\n",
        "        return None\n",
        "\n",
        "def normalize_header(text):\n",
        "    \"\"\"Chu·∫©n h√≥a header ƒë·ªÉ so s√°nh\"\"\"\n",
        "    if not text:\n",
        "        return \"\"\n",
        "    text = text.upper().strip()\n",
        "    text = remove_accents(text)\n",
        "    return text\n",
        "\n",
        "def is_code_column(header):\n",
        "    \"\"\"Ki·ªÉm tra xem c·ªôt c√≥ ph·∫£i l√† c·ªôt M√£ s·ªë kh√¥ng\"\"\"\n",
        "    normalized = normalize_header(header)\n",
        "    keywords = ['MS', 'MA', 'MAA']  # MA, M√É ƒë·ªÅu th√†nh MAA sau khi b·ªè d·∫•u\n",
        "    return any(kw in normalized for kw in keywords)\n",
        "\n",
        "def is_indicator_column(header):\n",
        "    \"\"\"Ki·ªÉm tra xem c·ªôt c√≥ ph·∫£i l√† c·ªôt Ch·ªâ ti√™u kh√¥ng\"\"\"\n",
        "    normalized = normalize_header(header)\n",
        "    keywords = [\n",
        "        'TAI SAN', 'TAISAN',\n",
        "        'NGUON VON', 'NGUONVON',\n",
        "        'CHI TIEU', 'CHITIEU',\n",
        "        'NOI DUNG', 'NOIDUNG',\n",
        "        'KHOAN MUC', 'KHOANMUC',\n",
        "        'TEN', 'DIEN GIAI', 'DIENGIAI'\n",
        "    ]\n",
        "    return any(kw in normalized for kw in keywords)\n",
        "\n",
        "def clean_code(text):\n",
        "    \"\"\"\n",
        "    L√†m s·∫°ch m√£ s·ªë:\n",
        "    - B·ªè text sau kho·∫£ng tr·∫Øng n·∫øu c√≥\n",
        "    - Ch·ªâ gi·ªØ s·ªë v√† d·∫•u ch·∫•m (cho m√£ s·ªë d·∫°ng 1.1, 2.3.4)\n",
        "    \"\"\"\n",
        "    if not text or not isinstance(text, str):\n",
        "        return \"\"\n",
        "\n",
        "    text = text.strip()\n",
        "\n",
        "    # N·∫øu c√≥ kho·∫£ng tr·∫Øng, ch·ªâ l·∫•y ph·∫ßn tr∆∞·ªõc kho·∫£ng tr·∫Øng ƒë·∫ßu ti√™n\n",
        "    if ' ' in text:\n",
        "        text = text.split(' ')[0]\n",
        "\n",
        "    # Ch·ªâ gi·ªØ s·ªë v√† d·∫•u ch·∫•m\n",
        "    text = re.sub(r'[^\\d.]', '', text)\n",
        "\n",
        "    return text.strip()\n",
        "\n",
        "def extract_table_data(html_path):\n",
        "    \"\"\"\n",
        "    Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ file HTML\n",
        "    Returns: list of records ho·∫∑c None n·∫øu kh√¥ng ƒë·ªß ƒëi·ªÅu ki·ªán\n",
        "    \"\"\"\n",
        "    with open(html_path, 'r', encoding='utf-8') as f:\n",
        "        soup = BeautifulSoup(f, 'html.parser')\n",
        "\n",
        "    table = soup.find('table')\n",
        "    if not table:\n",
        "        return None\n",
        "\n",
        "    rows = table.find_all('tr')\n",
        "    if not rows:\n",
        "        return None\n",
        "\n",
        "    # T√¨m header row (th∆∞·ªùng l√† row ƒë·∫ßu ti√™n ho·∫∑c c√≥ class header)\n",
        "    headers = []\n",
        "    data_start_idx = 0\n",
        "\n",
        "    for idx, row in enumerate(rows):\n",
        "        cells = row.find_all('td')\n",
        "        # Ki·ªÉm tra n·∫øu c√≥ cell n√†o c√≥ class header\n",
        "        if any('header' in cell.get('class', []) for cell in cells):\n",
        "            headers = [cell.get_text(separator=' ', strip=True) for cell in cells]\n",
        "            data_start_idx = idx + 1\n",
        "            break\n",
        "\n",
        "    if not headers:\n",
        "        # N·∫øu kh√¥ng t√¨m th·∫•y header v·ªõi class, l·∫•y row ƒë·∫ßu ti√™n\n",
        "        first_row_cells = rows[0].find_all('td')\n",
        "        headers = [cell.get_text(separator=' ', strip=True) for cell in first_row_cells]\n",
        "        data_start_idx = 1\n",
        "\n",
        "    # X√°c ƒë·ªãnh c√°c c·ªôt\n",
        "    code_col_idx = None\n",
        "    indicator_col_idx = None\n",
        "    year_prev_col_idx = None  # C·ªôt cu·ªëi c√πng (nƒÉm tr∆∞·ªõc)\n",
        "    year_curr_col_idx = None  # C·ªôt g·∫ßn cu·ªëi (nƒÉm sau)\n",
        "\n",
        "    # T√¨m c·ªôt M√£ s·ªë v√† Ch·ªâ ti√™u\n",
        "    for idx, header in enumerate(headers):\n",
        "        if code_col_idx is None and is_code_column(header):\n",
        "            code_col_idx = idx\n",
        "        if indicator_col_idx is None and is_indicator_column(header):\n",
        "            indicator_col_idx = idx\n",
        "\n",
        "    # X√°c ƒë·ªãnh c·ªôt nƒÉm: c·ªôt cu·ªëi v√† c·ªôt g·∫ßn cu·ªëi\n",
        "    # B·ªè qua c√°c c·ªôt tr·ªëng ·ªü cu·ªëi\n",
        "    non_empty_cols = []\n",
        "    for idx, header in enumerate(headers):\n",
        "        if header.strip() or idx in [code_col_idx, indicator_col_idx]:\n",
        "            non_empty_cols.append(idx)\n",
        "\n",
        "    if len(non_empty_cols) >= 2:\n",
        "        year_prev_col_idx = non_empty_cols[-1]  # C·ªôt cu·ªëi c√πng = nƒÉm tr∆∞·ªõc\n",
        "        year_curr_col_idx = non_empty_cols[-2]  # C·ªôt g·∫ßn cu·ªëi = nƒÉm sau\n",
        "\n",
        "    # Ki·ªÉm tra ƒë·ªß 3 c·ªôt c·∫ßn thi·∫øt\n",
        "    if code_col_idx is None or year_prev_col_idx is None or year_curr_col_idx is None:\n",
        "        return None\n",
        "\n",
        "    # N·∫øu kh√¥ng c√≥ c·ªôt ch·ªâ ti√™u, c√≥ th·ªÉ s·ª≠ d·ª•ng c·ªôt kh√°c (th∆∞·ªùng l√† c·ªôt ƒë·∫ßu ti√™n)\n",
        "    if indicator_col_idx is None:\n",
        "        # T√¨m c·ªôt ƒë·∫ßu ti√™n kh√¥ng ph·∫£i l√† c·ªôt m√£ s·ªë\n",
        "        for idx, header in enumerate(headers):\n",
        "            if idx != code_col_idx:\n",
        "                indicator_col_idx = idx\n",
        "                break\n",
        "\n",
        "    # Tr√≠ch xu·∫•t d·ªØ li·ªáu t·ª´ c√°c h√†ng\n",
        "    records = []\n",
        "    for row in rows[data_start_idx:]:\n",
        "        cells = row.find_all('td')\n",
        "        if len(cells) <= max(code_col_idx, indicator_col_idx or 0, year_prev_col_idx, year_curr_col_idx):\n",
        "            continue\n",
        "\n",
        "        # L·∫•y d·ªØ li·ªáu\n",
        "        code_raw = cells[code_col_idx].get_text(separator=' ', strip=True) if code_col_idx < len(cells) else \"\"\n",
        "        indicator = cells[indicator_col_idx].get_text(separator=' ', strip=True) if indicator_col_idx is not None and indicator_col_idx < len(cells) else \"\"\n",
        "\n",
        "        year_prev_text = cells[year_prev_col_idx].get_text(separator=' ', strip=True) if year_prev_col_idx < len(cells) else \"\"\n",
        "        year_curr_text = cells[year_curr_col_idx].get_text(separator=' ', strip=True) if year_curr_col_idx < len(cells) else \"\"\n",
        "\n",
        "        # L√†m s·∫°ch m√£ s·ªë (b·ªè text sau kho·∫£ng tr·∫Øng v√† k√Ω t·ª± kh√¥ng ph·∫£i s·ªë)\n",
        "        code = clean_code(code_raw)\n",
        "\n",
        "        # L√†m s·∫°ch s·ªë li·ªáu\n",
        "        year_prev = clean_number(year_prev_text)\n",
        "        year_curr = clean_number(year_curr_text)\n",
        "\n",
        "        # Ki·ªÉm tra n·∫øu nƒÉm tr∆∞·ªõc/nƒÉm sau tr√πng v·ªõi m√£ s·ªë ‚Üí coi nh∆∞ kh√¥ng c√≥\n",
        "        if code and year_prev is not None:\n",
        "            try:\n",
        "                # So s√°nh m√£ s·ªë v·ªõi nƒÉm tr∆∞·ªõc\n",
        "                # N·∫øu year_prev c√≥ ngo·∫∑c, b·ªè ngo·∫∑c ƒë·ªÉ so s√°nh\n",
        "                year_prev_compare = year_prev.replace('(', '').replace(')', '')\n",
        "                code_as_number = float(code)\n",
        "                year_prev_number = float(year_prev_compare)\n",
        "                if abs(code_as_number - year_prev_number) < 0.001:\n",
        "                    year_prev = None\n",
        "            except (ValueError, TypeError):\n",
        "                pass  # N·∫øu code ho·∫∑c year kh√¥ng ph·∫£i s·ªë, b·ªè qua\n",
        "\n",
        "        if code and year_curr is not None:\n",
        "            try:\n",
        "                # So s√°nh m√£ s·ªë v·ªõi nƒÉm sau\n",
        "                year_curr_compare = year_curr.replace('(', '').replace(')', '')\n",
        "                code_as_number = float(code)\n",
        "                year_curr_number = float(year_curr_compare)\n",
        "                if abs(code_as_number - year_curr_number) < 0.001:\n",
        "                    year_curr = None\n",
        "            except (ValueError, TypeError):\n",
        "                pass\n",
        "\n",
        "        # B·ªè qua n·∫øu kh√¥ng c√≥ m√£ s·ªë\n",
        "        if not code:\n",
        "            continue\n",
        "\n",
        "        # L∆∞u record ngay c·∫£ khi c·∫£ 2 nƒÉm ƒë·ªÅu None\n",
        "        records.append({\n",
        "            'code': code,\n",
        "            'indicator': indicator.strip(),\n",
        "            'year_previous': year_prev,\n",
        "            'year_current': year_curr\n",
        "        })\n",
        "\n",
        "    return records if records else None\n",
        "\n",
        "# =========================\n",
        "# DATABASE SETUP\n",
        "# =========================\n",
        "\n",
        "def init_database():\n",
        "    \"\"\"Kh·ªüi t·∫°o database v√† b·∫£ng\"\"\"\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    cursor.execute('''\n",
        "        CREATE TABLE IF NOT EXISTS financial_records (\n",
        "            id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
        "            org TEXT NOT NULL,\n",
        "            pdf_name TEXT NOT NULL,\n",
        "            source_file TEXT NOT NULL,\n",
        "            code TEXT NOT NULL,\n",
        "            indicator TEXT,\n",
        "            year_previous TEXT,\n",
        "            year_current TEXT,\n",
        "            created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP\n",
        "        )\n",
        "    ''')\n",
        "\n",
        "    # T·∫°o index ƒë·ªÉ t√¨m ki·∫øm nhanh h∆°n\n",
        "    cursor.execute('''\n",
        "        CREATE INDEX IF NOT EXISTS idx_org ON financial_records(org)\n",
        "    ''')\n",
        "\n",
        "    cursor.execute('''\n",
        "        CREATE INDEX IF NOT EXISTS idx_code ON financial_records(code)\n",
        "    ''')\n",
        "\n",
        "    cursor.execute('''\n",
        "        CREATE INDEX IF NOT EXISTS idx_source ON financial_records(source_file)\n",
        "    ''')\n",
        "\n",
        "    cursor.execute('''\n",
        "        CREATE INDEX IF NOT EXISTS idx_pdf_name ON financial_records(pdf_name)\n",
        "    ''')\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "    print(\"‚úÖ Database initialized\")\n",
        "\n",
        "def insert_records(records, org, pdf_name, source_file):\n",
        "    \"\"\"Ch√®n records v√†o database\"\"\"\n",
        "    conn = sqlite3.connect(DB_PATH)\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    for record in records:\n",
        "        cursor.execute('''\n",
        "            INSERT INTO financial_records (org, pdf_name, source_file, code, indicator, year_previous, year_current)\n",
        "            VALUES (?, ?, ?, ?, ?, ?, ?)\n",
        "        ''', (\n",
        "            org,\n",
        "            pdf_name,\n",
        "            source_file,\n",
        "            record['code'],\n",
        "            record['indicator'],\n",
        "            record['year_previous'],\n",
        "            record['year_current']\n",
        "        ))\n",
        "\n",
        "    conn.commit()\n",
        "    conn.close()\n",
        "\n",
        "# =========================\n",
        "# MAIN PROCESSING\n",
        "# =========================\n",
        "\n",
        "def extract_pdf_name(source_path):\n",
        "    \"\"\"\n",
        "    Tr√≠ch xu·∫•t t√™n PDF t·ª´ ƒë∆∞·ªùng d·∫´n\n",
        "    Input: \"DCS_000000014779169_VI_BaoCaoTaiChinh_KiemToan__2022./page008_table_000_vintern.html\"\n",
        "    Output: \"DCS_000000014779169_VI_BaoCaoTaiChinh_KiemToan__2022\"\n",
        "    \"\"\"\n",
        "    # L·∫•y th∆∞ m·ª•c ƒë·∫ßu ti√™n trong path (t√™n th∆∞ m·ª•c ch·ª©a file)\n",
        "    parts = source_path.split('/')\n",
        "    if len(parts) > 0:\n",
        "        folder_name = parts[0]\n",
        "        # Lo·∫°i b·ªè d·∫•u ch·∫•m ·ªü cu·ªëi n·∫øu c√≥ (nh∆∞ trong \"...2022./\")\n",
        "        pdf_name = folder_name.rstrip('.')\n",
        "        return pdf_name\n",
        "    return source_path\n",
        "\n",
        "def extract_org_code(pdf_name):\n",
        "    \"\"\"\n",
        "    Tr√≠ch xu·∫•t m√£ t·ªï ch·ª©c t·ª´ t√™n PDF\n",
        "    Input: \"VXB_000000013563283_CBTT_BCTC_2023_F\"\n",
        "    Output: \"VXB\"\n",
        "\n",
        "    Input: \"DCS_000000014779169_VI_BaoCaoTaiChinh_KiemToan__2022\"\n",
        "    Output: \"DCS\"\n",
        "    \"\"\"\n",
        "    # L·∫•y ph·∫ßn ƒë·∫ßu ti√™n tr∆∞·ªõc d·∫•u g·∫°ch d∆∞·ªõi\n",
        "    parts = pdf_name.split('_')\n",
        "    if len(parts) > 0:\n",
        "        return parts[0].strip()\n",
        "    return pdf_name\n",
        "\n",
        "def process_all_html_files():\n",
        "    \"\"\"X·ª≠ l√Ω t·∫•t c·∫£ c√°c file HTML v√† l∆∞u v√†o database\"\"\"\n",
        "\n",
        "    if not os.path.exists(HTML_BASE_DIR):\n",
        "        print(f\"‚ùå HTML directory not found: {HTML_BASE_DIR}\")\n",
        "        return\n",
        "\n",
        "    # Kh·ªüi t·∫°o database\n",
        "    init_database()\n",
        "\n",
        "    total_files = 0\n",
        "    processed_files = 0\n",
        "    skipped_files = 0\n",
        "    total_records = 0\n",
        "\n",
        "    # Duy·ªát qua t·∫•t c·∫£ c√°c th∆∞ m·ª•c\n",
        "    for base_name in os.listdir(HTML_BASE_DIR):\n",
        "        html_dir = os.path.join(HTML_BASE_DIR, base_name)\n",
        "\n",
        "        if not os.path.isdir(html_dir):\n",
        "            continue\n",
        "\n",
        "        print(f\"\\nüìÅ Processing: {base_name}\")\n",
        "\n",
        "        # Tr√≠ch xu·∫•t pdf_name v√† org t·ª´ t√™n th∆∞ m·ª•c\n",
        "        pdf_name = base_name.rstrip('.')\n",
        "        org = extract_org_code(pdf_name)\n",
        "\n",
        "        html_files = [f for f in os.listdir(html_dir) if f.endswith('.html')]\n",
        "\n",
        "        for html_file in tqdm(html_files, desc=f\"  {base_name}\"):\n",
        "            total_files += 1\n",
        "            html_path = os.path.join(html_dir, html_file)\n",
        "\n",
        "            try:\n",
        "                records = extract_table_data(html_path)\n",
        "\n",
        "                if records:\n",
        "                    # source_file s·∫Ω l√†: \"DCS_.../page008_table_000_vintern.html\"\n",
        "                    source_name = f\"{base_name}/{html_file}\"\n",
        "                    insert_records(records, org, pdf_name, source_name)\n",
        "                    processed_files += 1\n",
        "                    total_records += len(records)\n",
        "                else:\n",
        "                    skipped_files += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"    ‚ö†Ô∏è  Error processing {html_file}: {str(e)}\")\n",
        "                skipped_files += 1\n",
        "\n",
        "    print(\"\\n\" + \"=\" * 60)\n",
        "    print(f\"‚úÖ PROCESSING COMPLETE!\")\n",
        "    print(f\"üìä Statistics:\")\n",
        "    print(f\"   - Total files scanned: {total_files}\")\n",
        "    print(f\"   - Successfully processed: {processed_files}\")\n",
        "    print(f\"   - Skipped (insufficient data): {skipped_files}\")\n",
        "    print(f\"   - Total records inserted: {total_records}\")\n",
        "    print(f\"üíæ Database saved to: {DB_PATH}\")\n",
        "    print(\"=\" * 60)\n",
        "\n",
        "# =========================\n",
        "# RUN\n",
        "# =========================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    process_all_html_files()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9175b279",
        "outputId": "b081abb5-95c1-42f9-db4a-d85798bb8f67"
      },
      "source": [
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_file_path = '/content/html (10).zip'\n",
        "extract_dir = '/content/html'\n",
        "\n",
        "# Create the extraction directory if it doesn't exist\n",
        "os.makedirs(extract_dir, exist_ok=True)\n",
        "\n",
        "# Unzip the file\n",
        "with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_dir)\n",
        "\n",
        "print(f\"‚úÖ Extracted '{zip_file_path}' to '{extract_dir}'\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Extracted '/content/html (10).zip' to '/content/html'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b1190370",
        "outputId": "c50c6bf2-8e77-4059-e6d1-510dee9f3b7c"
      },
      "source": [
        "# List the contents of the extracted directory to verify\n",
        "import os\n",
        "print(os.listdir('/content/html'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DCS_000000014779169_VI_BaoCaoTaiChinh_KiemToan__2022.', 'CT6_000000014858118_Bao_cao_kiem_toan_tieng_Vietda_nen', 'BVL_000000014725614_VI_BCTC_hop_nhat_2024.signed', 'BT6_000000014970920_VI_BaoCaoTaiChinh_KiemToan_2024', 'APP_000000014774810_BCTC_Kiem_toan_2024', 'CMI_000000014698416_VI_BaoCaoTaiChinh_KiemToan_2024', 'CMC_000000014715923_VI_BaoCaoTaiChinh_KiemToan_2024.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# QUERY FINANCIAL DATABASE\n",
        "# =========================\n",
        "\n",
        "import sqlite3\n",
        "import pandas as pd\n",
        "from tabulate import tabulate\n",
        "\n",
        "DB_PATH = \"/content/financial_data.db\"\n",
        "\n",
        "# =========================\n",
        "# CONNECT TO DATABASE\n",
        "# =========================\n",
        "\n",
        "def get_connection():\n",
        "    \"\"\"T·∫°o k·∫øt n·ªëi ƒë·∫øn database\"\"\"\n",
        "    return sqlite3.connect(DB_PATH)\n",
        "\n",
        "# =========================\n",
        "# BASIC QUERIES\n",
        "# =========================\n",
        "\n",
        "def show_table_info():\n",
        "    \"\"\"Hi·ªÉn th·ªã th√¥ng tin b·∫£ng\"\"\"\n",
        "    conn = get_connection()\n",
        "    cursor = conn.cursor()\n",
        "\n",
        "    # L·∫•y schema\n",
        "    cursor.execute(\"PRAGMA table_info(financial_records)\")\n",
        "    columns = cursor.fetchall()\n",
        "\n",
        "    print(\"üìä TABLE SCHEMA: financial_records\")\n",
        "    print(\"=\" * 70)\n",
        "    for col in columns:\n",
        "        print(f\"  {col[1]:20} {col[2]:10} {'NOT NULL' if col[3] else ''} {'PRIMARY KEY' if col[5] else ''}\")\n",
        "\n",
        "    # ƒê·∫øm t·ªïng s·ªë records\n",
        "    cursor.execute(\"SELECT COUNT(*) FROM financial_records\")\n",
        "    total = cursor.fetchone()[0]\n",
        "    print(f\"\\nüìà Total Records: {total:,}\")\n",
        "\n",
        "    # ƒê·∫øm s·ªë file ngu·ªìn\n",
        "    cursor.execute(\"SELECT COUNT(DISTINCT source_file) FROM financial_records\")\n",
        "    files = cursor.fetchone()[0]\n",
        "    print(f\"üìÅ Unique Source Files: {files:,}\")\n",
        "\n",
        "    # ƒê·∫øm s·ªë m√£ s·ªë unique\n",
        "    cursor.execute(\"SELECT COUNT(DISTINCT code) FROM financial_records\")\n",
        "    codes = cursor.fetchone()[0]\n",
        "    print(f\"üî¢ Unique Codes: {codes:,}\")\n",
        "\n",
        "    conn.close()\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "def show_sample_records(limit=10):\n",
        "    \"\"\"Hi·ªÉn th·ªã c√°c records m·∫´u\"\"\"\n",
        "    conn = get_connection()\n",
        "\n",
        "    query = f\"\"\"\n",
        "        SELECT\n",
        "            id,\n",
        "            source_file,\n",
        "            code,\n",
        "            indicator,\n",
        "            year_previous,\n",
        "            year_current\n",
        "        FROM financial_records\n",
        "        LIMIT {limit}\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_sql_query(query, conn)\n",
        "    conn.close()\n",
        "\n",
        "    print(f\"\\nüìã SAMPLE RECORDS (First {limit}):\")\n",
        "    print(\"=\" * 120)\n",
        "    print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))\n",
        "\n",
        "def search_by_code(code):\n",
        "    \"\"\"T√¨m ki·∫øm theo m√£ s·ªë\"\"\"\n",
        "    conn = get_connection()\n",
        "\n",
        "    query = \"\"\"\n",
        "        SELECT\n",
        "            id,\n",
        "            source_file,\n",
        "            code,\n",
        "            indicator,\n",
        "            year_previous,\n",
        "            year_current\n",
        "        FROM financial_records\n",
        "        WHERE code = ?\n",
        "        ORDER BY source_file\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_sql_query(query, conn, params=(code,))\n",
        "    conn.close()\n",
        "\n",
        "    if len(df) == 0:\n",
        "        print(f\"‚ùå No records found for code: {code}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüîç SEARCH RESULTS for Code: {code}\")\n",
        "    print(\"=\" * 120)\n",
        "    print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))\n",
        "    print(f\"\\nFound {len(df)} record(s)\")\n",
        "\n",
        "def search_by_indicator(keyword):\n",
        "    \"\"\"T√¨m ki·∫øm theo ch·ªâ ti√™u (t√¨m ki·∫øm g·∫ßn ƒë√∫ng)\"\"\"\n",
        "    conn = get_connection()\n",
        "\n",
        "    query = \"\"\"\n",
        "        SELECT\n",
        "            id,\n",
        "            source_file,\n",
        "            code,\n",
        "            indicator,\n",
        "            year_previous,\n",
        "            year_current\n",
        "        FROM financial_records\n",
        "        WHERE indicator LIKE ?\n",
        "        ORDER BY source_file, code\n",
        "        LIMIT 50\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_sql_query(query, conn, params=(f'%{keyword}%',))\n",
        "    conn.close()\n",
        "\n",
        "    if len(df) == 0:\n",
        "        print(f\"‚ùå No records found for indicator containing: {keyword}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüîç SEARCH RESULTS for Indicator: '{keyword}'\")\n",
        "    print(\"=\" * 120)\n",
        "    print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))\n",
        "    print(f\"\\nFound {len(df)} record(s) (limited to 50)\")\n",
        "\n",
        "def get_records_by_source(source_file):\n",
        "    \"\"\"L·∫•y t·∫•t c·∫£ records t·ª´ m·ªôt file ngu·ªìn\"\"\"\n",
        "    conn = get_connection()\n",
        "\n",
        "    query = \"\"\"\n",
        "        SELECT\n",
        "            id,\n",
        "            code,\n",
        "            indicator,\n",
        "            year_previous,\n",
        "            year_current\n",
        "        FROM financial_records\n",
        "        WHERE source_file = ?\n",
        "        ORDER BY id\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_sql_query(query, conn, params=(source_file,))\n",
        "    conn.close()\n",
        "\n",
        "    if len(df) == 0:\n",
        "        print(f\"‚ùå No records found for source: {source_file}\")\n",
        "        return\n",
        "\n",
        "    print(f\"\\nüìÑ RECORDS from: {source_file}\")\n",
        "    print(\"=\" * 120)\n",
        "    print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))\n",
        "    print(f\"\\nTotal: {len(df)} record(s)\")\n",
        "\n",
        "def list_all_sources():\n",
        "    \"\"\"Li·ªát k√™ t·∫•t c·∫£ c√°c file ngu·ªìn\"\"\"\n",
        "    conn = get_connection()\n",
        "\n",
        "    query = \"\"\"\n",
        "        SELECT\n",
        "            source_file,\n",
        "            COUNT(*) as record_count,\n",
        "            MIN(year_previous) as min_year_prev,\n",
        "            MAX(year_previous) as max_year_prev\n",
        "        FROM financial_records\n",
        "        GROUP BY source_file\n",
        "        ORDER BY source_file\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_sql_query(query, conn)\n",
        "    conn.close()\n",
        "\n",
        "    print(\"\\nüìö ALL SOURCE FILES:\")\n",
        "    print(\"=\" * 100)\n",
        "    print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))\n",
        "    print(f\"\\nTotal: {len(df)} file(s)\")\n",
        "\n",
        "def get_summary_by_code():\n",
        "    \"\"\"Th·ªëng k√™ theo m√£ s·ªë\"\"\"\n",
        "    conn = get_connection()\n",
        "\n",
        "    query = \"\"\"\n",
        "        SELECT\n",
        "            code,\n",
        "            COUNT(*) as occurrences,\n",
        "            COUNT(DISTINCT source_file) as file_count,\n",
        "            AVG(year_previous) as avg_year_prev,\n",
        "            AVG(year_current) as avg_year_curr\n",
        "        FROM financial_records\n",
        "        GROUP BY code\n",
        "        HAVING occurrences > 1\n",
        "        ORDER BY occurrences DESC\n",
        "        LIMIT 30\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_sql_query(query, conn)\n",
        "    conn.close()\n",
        "\n",
        "    print(\"\\nüìä SUMMARY BY CODE (Top 30 most common):\")\n",
        "    print(\"=\" * 100)\n",
        "    print(tabulate(df, headers='keys', tablefmt='grid', showindex=False, floatfmt='.2f'))\n",
        "\n",
        "def export_to_csv(output_path=\"/content/financial_data_export.csv\"):\n",
        "    \"\"\"Export to√†n b·ªô d·ªØ li·ªáu ra CSV\"\"\"\n",
        "    conn = get_connection()\n",
        "\n",
        "    query = \"\"\"\n",
        "        SELECT\n",
        "            id,\n",
        "            source_file,\n",
        "            code,\n",
        "            indicator,\n",
        "            year_previous,\n",
        "            year_current,\n",
        "            org,\n",
        "            created_at\n",
        "        FROM financial_records\n",
        "        ORDER BY source_file, id\n",
        "    \"\"\"\n",
        "\n",
        "    df = pd.read_sql_query(query, conn)\n",
        "    conn.close()\n",
        "\n",
        "    df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
        "    print(f\"‚úÖ Exported {len(df)} records to: {output_path}\")\n",
        "\n",
        "\n",
        "def custom_query(sql):\n",
        "    \"\"\"Th·ª±c thi c√¢u query t√πy ch·ªânh\"\"\"\n",
        "    conn = get_connection()\n",
        "\n",
        "    try:\n",
        "        df = pd.read_sql_query(sql, conn)\n",
        "        conn.close()\n",
        "\n",
        "        print(\"\\nüîß CUSTOM QUERY RESULT:\")\n",
        "        print(\"=\" * 120)\n",
        "        print(tabulate(df, headers='keys', tablefmt='grid', showindex=False))\n",
        "        print(f\"\\nReturned {len(df)} row(s)\")\n",
        "        return df\n",
        "    except Exception as e:\n",
        "        conn.close()\n",
        "        print(f\"‚ùå Query Error: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# =========================\n",
        "# INTERACTIVE MENU\n",
        "# =========================\n",
        "\n",
        "def show_menu():\n",
        "    \"\"\"Hi·ªÉn th·ªã menu t∆∞∆°ng t√°c\"\"\"\n",
        "    print(\"\\n\" + \"=\" * 70)\n",
        "    print(\"üíæ FINANCIAL DATABASE QUERY TOOL\")\n",
        "    print(\"=\" * 70)\n",
        "    print(\"1. Show database info\")\n",
        "    print(\"2. Show sample records\")\n",
        "    print(\"3. Search by code\")\n",
        "    print(\"4. Search by indicator (keyword)\")\n",
        "    print(\"5. List all source files\")\n",
        "    print(\"6. Get records from specific source file\")\n",
        "    print(\"7. Summary by code\")\n",
        "    print(\"8. Export to CSV\")\n",
        "    print(\"9. Run custom SQL query\")\n",
        "    print(\"0. Exit\")\n",
        "    print(\"=\" * 70)\n",
        "\n",
        "def main():\n",
        "    \"\"\"Main interactive function\"\"\"\n",
        "    while True:\n",
        "        show_menu()\n",
        "        choice = input(\"\\nEnter your choice: \").strip()\n",
        "\n",
        "        if choice == '1':\n",
        "            show_table_info()\n",
        "\n",
        "        elif choice == '2':\n",
        "            limit = input(\"Number of records to show (default 10): \").strip()\n",
        "            limit = int(limit) if limit.isdigit() else 10\n",
        "            show_sample_records(limit)\n",
        "\n",
        "        elif choice == '3':\n",
        "            code = input(\"Enter code to search: \").strip()\n",
        "            if code:\n",
        "                search_by_code(code)\n",
        "\n",
        "        elif choice == '4':\n",
        "            keyword = input(\"Enter keyword to search in indicator: \").strip()\n",
        "            if keyword:\n",
        "                search_by_indicator(keyword)\n",
        "\n",
        "        elif choice == '5':\n",
        "            list_all_sources()\n",
        "\n",
        "        elif choice == '6':\n",
        "            source = input(\"Enter source file name: \").strip()\n",
        "            if source:\n",
        "                get_records_by_source(source)\n",
        "\n",
        "        elif choice == '7':\n",
        "            get_summary_by_code()\n",
        "\n",
        "        elif choice == '8':\n",
        "            output = input(\"Output path (default: /content/financial_data_export.csv): \").strip()\n",
        "            output = output if output else \"/content/financial_data_export.csv\"\n",
        "            export_to_csv(output)\n",
        "\n",
        "        elif choice == '9':\n",
        "            print(\"\\nEnter SQL query (press Enter twice to execute):\")\n",
        "            lines = []\n",
        "            while True:\n",
        "                line = input()\n",
        "                if line == \"\":\n",
        "                    break\n",
        "                lines.append(line)\n",
        "            sql = \"\\n\".join(lines)\n",
        "            if sql.strip():\n",
        "                custom_query(sql)\n",
        "\n",
        "        elif choice == '0':\n",
        "            print(\"\\nüëã Goodbye!\")\n",
        "            break\n",
        "\n",
        "        else:\n",
        "            print(\"‚ùå Invalid choice. Please try again.\")\n",
        "\n",
        "        input(\"\\nPress Enter to continue...\")\n",
        "\n",
        "# =========================\n",
        "# QUICK ACCESS FUNCTIONS\n",
        "# =========================\n",
        "\n",
        "# B·∫°n c√≥ th·ªÉ g·ªçi tr·ª±c ti·∫øp c√°c function n√†y:\n",
        "\n",
        "# show_table_info()\n",
        "# show_sample_records(20)\n",
        "# search_by_code(\"100\")\n",
        "# search_by_indicator(\"T√†i s·∫£n\")\n",
        "# list_all_sources()\n",
        "# get_summary_by_code()\n",
        "# export_to_csv()\n",
        "\n",
        "# =========================\n",
        "# RUN\n",
        "# =========================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Ch·∫°y menu t∆∞∆°ng t√°c\n",
        "    main()\n",
        "\n",
        "    # HO·∫∂C g·ªçi tr·ª±c ti·∫øp c√°c function:\n",
        "    # show_table_info()\n",
        "    # show_sample_records(10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-jL2sNUNJ_R1",
        "outputId": "62e76091-5eb2-4b0d-99d1-d8357c23e38c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "======================================================================\n",
            "üíæ FINANCIAL DATABASE QUERY TOOL\n",
            "======================================================================\n",
            "1. Show database info\n",
            "2. Show sample records\n",
            "3. Search by code\n",
            "4. Search by indicator (keyword)\n",
            "5. List all source files\n",
            "6. Get records from specific source file\n",
            "7. Summary by code\n",
            "8. Export to CSV\n",
            "9. Run custom SQL query\n",
            "0. Exit\n",
            "======================================================================\n",
            "\n",
            "Enter your choice: 8\n",
            "Output path (default: /content/financial_data_export.csv): \n",
            "‚úÖ Exported 1143 records to: /content/financial_data_export.csv\n",
            "\n",
            "Press Enter to continue...\n",
            "\n",
            "======================================================================\n",
            "üíæ FINANCIAL DATABASE QUERY TOOL\n",
            "======================================================================\n",
            "1. Show database info\n",
            "2. Show sample records\n",
            "3. Search by code\n",
            "4. Search by indicator (keyword)\n",
            "5. List all source files\n",
            "6. Get records from specific source file\n",
            "7. Summary by code\n",
            "8. Export to CSV\n",
            "9. Run custom SQL query\n",
            "0. Exit\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "947f182f",
        "outputId": "2b2c7a3b-3aa8-44f3-ae3b-67d17e18e817"
      },
      "source": [
        "import os\n",
        "import shutil\n",
        "\n",
        "directory_to_remove = '/content/html/html (10)/VXB_000000013563283_CBTT_BCTC_2023_F'\n",
        "\n",
        "if os.path.exists(directory_to_remove):\n",
        "    shutil.rmtree(directory_to_remove)\n",
        "    print(f\"‚úÖ Th∆∞ m·ª•c '{directory_to_remove}' ƒë√£ ƒë∆∞·ª£c x√≥a th√†nh c√¥ng.\")\n",
        "else:\n",
        "    print(f\"‚ùå Th∆∞ m·ª•c '{directory_to_remove}' kh√¥ng t·ªìn t·∫°i.\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Th∆∞ m·ª•c '/content/html/html (10)/VXB_000000013563283_CBTT_BCTC_2023_F' ƒë√£ ƒë∆∞·ª£c x√≥a th√†nh c√¥ng.\n"
          ]
        }
      ]
    }
  ]
}